#! /usr/bin/env python
print("Beginning program")
import sys
from models import OneComponentModel, param_map
from sample import KalmanLikelihood1
import bilby
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
from corner import corner
import argparse
from pathlib import Path
plt.rc('text', usetex=False)
print("Importing modules completed")

def run(params):
    outdirectory = Path(params.out_directory)
    outdirectory.mkdir(parents=True, exist_ok=True)

    #Load simulated tempo fitted freqs and times and errors
    data1 = np.loadtxt(params.freqfile)
    times_tempo = data1[:, 0]*86400
    data_tempo = data1[:, 1]*2*np.pi
    R_tempo = (data1[:, 2]*2*np.pi)**2

    times_tempo = times_tempo.astype(np.float64)
    data_tempo = data_tempo.astype(np.float64)
    R_tempo = R_tempo.astype(np.float64)

    Nobs_tempo = len(times_tempo)
    measurement_cov = R_tempo.copy()
    model = OneComponentModel(times_tempo, data_tempo, measurement_cov)
    likelihood = KalmanLikelihood1(model)

    print("measurement_cov =", measurement_cov)

    #Get an estimate for omgc_dot by fitting a linear trend
    p, V = np.polyfit(times_tempo, data_tempo, 1, w=1/np.sqrt(np.squeeze(measurement_cov)), cov=True)
    omgd_low = p[0] - np.sqrt(V[0,0]) * 1000
    omgd_high = p[0] + np.sqrt(V[0,0]) * 1000

    #Set priors
    Qc_min = 1e-30
    Qc_max = 1e-16
    omgc_dot_min = omgd_low
    omgc_dot_max = omgd_high
    priors = bilby.core.prior.PriorDict()
    priors['Qc'] = bilby.core.prior.LogUniform(minimum=Qc_min, maximum=Qc_max, name='Qc', latex_label='$Q_c$')
    priors['omgc_dot'] = bilby.core.prior.Uniform(minimum=omgc_dot_min, maximum=omgc_dot_max, name='omgc_dot', latex_label='$\\langle \\dot{\\Omega}_c \\rangle$')
    priors['omgc_0'] = bilby.core.prior.DeltaFunction(data_tempo[0], name='omgc_0', latex_label='$\\Omega_{\\rm{c}, 0}$')
    priors['EFAC'] = bilby.core.prior.DeltaFunction(1, name='EFAC', latex_label='EFAC')
    priors['EQUAD'] = bilby.core.prior.DeltaFunction(0, name='EQUAD', latex_label='EQUAD')

    #Run the sampler
    result = bilby.run_sampler(likelihood, priors, sampler='dynesty',
                               sample='rwalk', walks=params.Nwalks, npoints=params.Npoints,
                               resume=params.resume_run, outdir=params.out_directory,
                               label=f'{params.tag}_tempo', check_point_plot=False)

    samples_tempo = result.posterior.to_numpy()[:, :2].copy()
    samples_tempo[:, 0:1] = np.log10(samples_tempo[:, 0:1])
    nsamples = len(samples_tempo[:, 0])
    print("samples_tempo[-1] =", samples_tempo[-1])
    print("10**samples_tempo[-1] =", 10**samples_tempo[-1])
    print("samples_tempo =", samples_tempo)
    print("measurement_cov =", measurement_cov)
    print("measurement_cov_new =", measurement_cov*10**samples_tempo[-1,-2]+10**samples_tempo[-1,-1])

    #Plot the output of the sampler as a corner plot.
    labels = ['$\log_{10}(Q_c)$ $[\\rm{rad^2~s^{-3}}]$',
              '$\\langle \\dot\\Omega_c\\rangle$ $[\\rm{rad~s^{-2}}]$']
    fig = corner(samples_tempo, bins=50,
                 range = [(-23.2, -22.2), (-2.449e-12, -2.4456e-12)],
                 #range = [(np.log10(Qc_min), np.log10(Qc_max)), (omgc_dot_min, omgc_dot_max)],
                 color='b', smooth=True, levels=[1-np.exp(-0.5), 1 - np.exp(-2), 1 - np.exp(-9/2)])
    axarr = np.reshape(fig.axes, (len(labels), len(labels)))
    axarr[1, 1].get_xaxis().get_offset_text().set_fontsize(13)
    axarr[1, 0].get_yaxis().get_offset_text().set_position((-0.5, 10))
    axarr[1, 0].get_yaxis().get_offset_text().set_fontsize(13)
    for ii, label in enumerate(labels):
        axarr[ii,ii].set_title(label, fontsize=15)
    axarr[1,0].yaxis.set_tick_params(labelsize=13)
    axarr[1,1].xaxis.set_tick_params(labelsize=13)
    axarr[1,0].xaxis.set_tick_params(labelsize=13)
    plt.savefig(f'{params.out_directory}/{params.tag}_tempo_corner_50bins.png')
    plt.close()



    print("\n")
    #Print the natural log of the Bayesian evidence and its error.
    print("log_evidence =", result.log_evidence)
    print("log_evidence_err =", result.log_evidence_err)
    print("log10_evidence =", result.log_evidence/np.log(10))
    print("log10_evidence_err =", result.log_evidence_err/np.log(10))
    print("\n")



    log_Qc_samples = samples_tempo[:, 0]
    omgc_dot_samples = samples_tempo[:, 1]

    #Find sample with the highest likelihood value.
    log_Qc_peak = samples_tempo[-1, 0]
    omgc_dot_peak = samples_tempo[-1, 1]
    print("log_Qc_peak =", log_Qc_peak)
    print("omgc_dot_peak =", omgc_dot_peak)
    print("\n")

    #Calculate percentiles using the samples generated by the sampler.
    Qc5, Qc50, Qc95 = np.percentile(log_Qc_samples, [5,50,95])
    omgc_dot5, omgc_dot50, omgc_dot95 = np.percentile(omgc_dot_samples, [5,50,95])
    print("Qc5 =", Qc5)
    print("Qc95 =", Qc95)
    print("omgc_dot5 =", omgc_dot5)
    print("omgc_dot95 =", omgc_dot95)

    #Calculate 90% confidence intervals. Be careful if the peak is outside this range.
    log_Qc_width = Qc95-Qc5
    omgc_dot_width = omgc_dot95-omgc_dot5
    print("log_Qc_width =", log_Qc_width)
    print("omgc_dot_width =", omgc_dot_width)
    print("\n")



    #Calculate properties of the samples using the bins of the histogram.
    Nbins = 50

    log_Qc_min = np.log10(Qc_min)
    log_Qc_max = np.log10(Qc_max)

    #Make a list of the bin positions
    #log_Qc_bins = np.linspace(log_Qc_min, log_Qc_max, Nbins+1)
    #omgc_dot_bins = np.linspace(omgc_dot_min, omgc_dot_max, Nbins+1)
    log_Qc_bins = np.linspace(-23.2, -22.2, Nbins+1)
    omgc_dot_bins = np.linspace(-2.449e-12, -2.4456e-12, Nbins+1)

    #These will contain a manual count of how many points are in each bin
    log_Qc_bin_counts = np.zeros(Nbins)
    omgc_dot_bin_counts = np.zeros(Nbins)

    #Count how many samples are in each bin
    for x in log_Qc_samples:
        for i in range(Nbins):
            if log_Qc_bins[i] < x < log_Qc_bins[i+1]:
                log_Qc_bin_counts[i] += 1

    for x in omgc_dot_samples:
        for i in range(Nbins):
            if omgc_dot_bins[i] < x < omgc_dot_bins[i+1]:
                omgc_dot_bin_counts[i] += 1

    #Calculate the full width at half maximum (FWHM).
    #Find the highest count in each histogram
    max_Qc_count = max(log_Qc_bin_counts)
    max_omgc_dot_count = max(omgc_dot_bin_counts)

    #Work out which bins are above or equal to half the maximum of the histogram
    #Return the parameter values of the lowest and highest bins and the difference.
    #This FWHM calculation should only be applied if there is only one peak above half of the maximum.
    greater_than_HM = []
    for i in range(Nbins):
        if log_Qc_bin_counts[i] >= max_Qc_count/2.0:
            greater_than_HM.append(i)
    lower_limit = min(greater_than_HM)
    upper_limit = max(greater_than_HM)+1
    print("log_Qc_bins[lower_limit] =", log_Qc_bins[lower_limit])
    print("log_Qc_bins[upper_limit] =", log_Qc_bins[upper_limit])
    print("FWHM_Qc =", log_Qc_bins[upper_limit] - log_Qc_bins[lower_limit])

    greater_than_HM = []
    for i in range(Nbins):
        if omgc_dot_bin_counts[i] >= max_omgc_dot_count/2.0:
            greater_than_HM.append(i)
    lower_limit = min(greater_than_HM)
    upper_limit = max(greater_than_HM)+1
    print("omgc_dot_bins[lower_limit] =", omgc_dot_bins[lower_limit])
    print("omgc_dot_bins[upper_limit] =", omgc_dot_bins[upper_limit])
    print("FWHM_omgc_dot =", omgc_dot_bins[upper_limit] - omgc_dot_bins[lower_limit])
    print("\n")

    #Find the location of the maximum of the histogram.
    log_Qc_i = np.argmax(log_Qc_bin_counts)
    omgc_dot_i = np.argmax(omgc_dot_bin_counts)

    log_Qc_max = (log_Qc_bins[log_Qc_i]+log_Qc_bins[log_Qc_i+1])/2
    omgc_dot_max = (omgc_dot_bins[omgc_dot_i]+omgc_dot_bins[omgc_dot_i+1])/2

    #Upper and lower limits of bin with highest count
    print("log_Qc_bins[log_Qc_i] =", log_Qc_bins[log_Qc_i])
    print("log_Qc_bins[log_Qc_i+1] =", log_Qc_bins[log_Qc_i+1])
    print("omgc_dot_bins[omgc_dot_i] =", omgc_dot_bins[omgc_dot_i])
    print("omgc_dot_bins[omgc_dot_i+1] =", omgc_dot_bins[omgc_dot_i+1])

    #Mid point of peak bin
    print("log_Qc_max =", log_Qc_max)
    print("omgc_dot_max =", omgc_dot_max)
    print("10**log_Qc_max =", 10**log_Qc_max)

    #Difference between peak bin and max ll parameter value
    print("log_Qc_max - log_Qc_samples[-1] =", log_Qc_max - log_Qc_samples[-1])
    print("omgc_dot_max - omgc_dot_samples[-1] =", omgc_dot_max - omgc_dot_samples[-1])



if __name__=="__main__":
    #Parse command line arguments
    parser = argparse.ArgumentParser()
    #Input_data
    parser.add_argument("--freqfile", default=None, type=str, help="file with pulsar frequencies")
    #MCMC information
    parser.add_argument("--Nwalks", default=None, type=int, help="number of walks for mcmc")
    parser.add_argument("--Npoints", default=None, type=int, help="number of points for mcmc")
    parser.add_argument("--resume-run", help="resume mcmc run from where it left off", action="store_true", default=False)
    #Save information
    parser.add_argument("--out_directory", help="output directory", default="./outdir/", type=str)
    parser.add_argument("--tag", help="tag to include in saving information", default='real')
    args = parser.parse_args()
    run(args)

